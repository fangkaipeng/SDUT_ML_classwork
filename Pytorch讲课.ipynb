{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f96271b",
   "metadata": {},
   "source": [
    "# Pytorch介绍\n",
    "## 简介\n",
    "PyTorch是一个很著名的支持GPU加速和自动求导的深度学习框架，在最近几年收到学术界的热捧，主要是因为其动态图机制符合思维逻辑，方便调试，适合于需要将想法迅速实现的研究者。PyTorch是Torch7团队开发的。Torch是一个开源科学计算框架，可以追溯到2002年纽约大学的项目。Torch的核心在于在构建深度神经网络及其优化和训练，为图像，语音，视频处理以及大规模机器学习问题提供快速高效的计算方案。为了追求更高的速度，灵活性和可扩展性，Torch采用Lua作为它的开发语言，但lua语言的受众比较局限。为了满足当今业界里Python先行(Python First)的原则，PyTorch应运而生，由Facebook人工智能研究员(FAIR)于2017年在GitHub上开源。顾名思义，PyTorch使用python作为开发语言，近年来和tensorflow, keras, caffe等热门框架一起，成为深度学习开发的主流平台之一。\n",
    "## 特点\n",
    "- 动态计算：这是PyTorch别于Tensorflow, caffe等框架最大的一点。神经网络在运行时定义创建，并且可以随时查看训练中的tensor值，快速学习网络。PyTorch通过变量的自动反向求导机制，可以零延迟地改变神经网络的学习行为。（Tensorflow2.0中，已经将Eager Execurion变为默认执行模式，由编写静态计算图转向动态计算图。）\n",
    "- 生态：相比较于比较年轻的PyTorch，TensorFlow由于发布较早，用户基数大，社区庞大，其生态相当完整，从底层张量运算到云端模型部署，TensorFlow都可以做到。\n",
    "- 适用人群：工业界需要部署效率，所以倾向于TensorFlow；学术界需要模型迭代，所以倾向于PyTorch。\n",
    "- 使用难度：PyTorch的设计追求最少的封装，尽量避免重复造轮子。PyTorch的设计遵循张量(tensor)→变量(variable)→神经网络模块(nn.Module) 三个由低到高的抽象层次。不像Tensorflow中定义了许多全新而复杂的变量，对于新手来说，PyTorch更加直观，更容易深入API来理解底层代码。\n",
    "\n",
    "下面是Pytorch和TensorFolow的对比：\n",
    "\n",
    "在Papers with Code网站上的论文中，大部分都使用的是PyTorch框架，并且还在逐渐上升，TensorFlow的市场份额在逐年下降。\n",
    "<img src=\"https://img.fangkaipeng.com/blog_img/20220529110034.png\" alt=\"image-20220529110020288\" style=\"zoom: 67%;\" />\n",
    "\n",
    "TensorFlow 自成立以来一直是面向部署的应用程序的首选框架，TensorFlow Serving和TensorFlow Lite可让用户轻松地在云、服务器、移动设备和 IoT 设备上进行部署。各大公司在招聘深度学习工程师时，大部分都要求掌握TensorFlow框架。部署便捷性上，TensorFlow完胜。\n",
    "<img src=\"https://img.fangkaipeng.com/blog_img/20220529110038.png\" alt=\"image-20220529110027605\" style=\"zoom:67%;\" />\n",
    "\n",
    "总的来说，TensorFlow和PyTorch的发展前景都很友好，PyTorch在学术界非常受欢迎，作为深度学习研究者，掌握PyTorch是必要的。\n",
    "\n",
    "## 安装\n",
    "\n",
    "官网：https://pytorch.org/get-started/locally/\n",
    "\n",
    "在下图中选择需要安装环境的主机的配置情况，然后使用命令行进行安装：\n",
    "<img src=\"https://img.fangkaipeng.com/blog_img/20220529110402.png\" alt=\"image-20220529110402081\" style=\"zoom: 67%;\" />\n",
    "\n",
    "说明：\n",
    "\n",
    "- PyTorch Build 中的三个选项从左往右代表稳定版，先行版，长期支持版，一般选择第一个即可。\n",
    "- Package表示使用什么包管理工具安装，依据本机的Python环境选择。\n",
    "- Compute Platform：表示安装GPU版还是CPU版本，只支持nvidia的显卡，如果本机没有可用显卡，就安装CPU版本，否则选择CUDA安装。注意如果要安装GPU版本，还需要安装对应的GPU驱动，包括对应的CUDA和cuDNN。参考：https://zhuanlan.zhihu.com/p/106133822"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c9a0f",
   "metadata": {},
   "source": [
    "# Tensor 基础操作\n",
    "\n",
    "Pytorch 的一大作用就是可以代替 Numpy 库，所以首先介绍 Tensors ，也就是张量，它相当于 Numpy 的多维数组(ndarrays)。两者的区别就是 Tensors 可以应用到 GPU 上加快计算速度。\n",
    "\n",
    "##  声明和定义\n",
    "首先是对 Tensors 的声明和定义方法，分别有以下几种：\n",
    "- `torch.empty()`: 声明一个未初始化的矩阵。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bb159a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  0.0000e+00,  2.1019e-44],\n",
      "        [ 0.0000e+00, -8.0644e-10,  6.1237e-43],\n",
      "        [ 2.0027e-19,  7.8026e+34,  0.0000e+00],\n",
      "        [ 0.0000e+00,  2.1019e-44,  0.0000e+00],\n",
      "        [-8.0639e-10,  6.1237e-43,  4.4377e+27]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86176\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 创建一个 5*3 的矩阵\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab69af",
   "metadata": {},
   "source": [
    "- `torch.rand()`：随机初始化一个矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32bd9b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8742, 0.1341, 0.3243],\n",
      "        [0.7941, 0.1502, 0.9467],\n",
      "        [0.2283, 0.1364, 0.9817],\n",
      "        [0.6870, 0.4786, 0.2607],\n",
      "        [0.1655, 0.1305, 0.6335]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个随机初始化的 5*3 矩阵\n",
    "rand_x = torch.rand(5, 3)\n",
    "print(rand_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75505f9e",
   "metadata": {},
   "source": [
    "- `torch.zeros()`：创建数值皆为 0 的矩阵，类似的也可以创建数值都是 1 的矩阵，调用 `torch.one`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550ea7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个数值皆是 0，类型为 long 的矩阵\n",
    "zero_x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(zero_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad3211",
   "metadata": {},
   "source": [
    "- `torch.tensor()`：直接传递 tensor 数值来创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdba8fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# tensor 数值是 [5.5, 3]\n",
    "tensor1 = torch.tensor([5.5, 3])\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f566e5",
   "metadata": {},
   "source": [
    "## 操作(Operations)\n",
    "操作也包含了很多语法，但这里作为快速入门，仅仅以加法操作作为例子进行介绍，更多的操作介绍可以点击下面网址查看官方文档，包括转置、索引、切片、数学计算、线性代数、随机数等等：\n",
    "https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65244255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n几种加法操作：\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "几种加法操作：\n",
    "\"\"\"\n",
    "tensor3 = torch.ones(5, 3)\n",
    "tensor4 = torch.ones(5, 3)\n",
    "\n",
    "tensor3 + tensor4\n",
    "\n",
    "torch.add(tensor3, tensor4)\n",
    "\n",
    "# 新声明一个 tensor 变量保存加法操作的结果\n",
    "result = torch.empty(5, 3)\n",
    "\n",
    "torch.add(tensor3, tensor4, out=result)\n",
    "\n",
    "# 直接修改变量\n",
    "tensor3.add_(tensor4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0c6fae",
   "metadata": {},
   "source": [
    "注意：可以改变 tensor 变量的操作都带有一个后缀 `_` , 例如 `x.copy_(y)` , `x.t_()` 都可以改变 x 变量,除了加法运算操作，对于 Tensor 的访问，和 Numpy 对数组类似，可以使用索引来访问某一维的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbaaf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n修改尺寸\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0445,  1.2542,  0.2437,  0.4232],\n",
       "        [ 0.8193,  1.3041, -1.0165,  0.0656],\n",
       "        [ 0.6642, -0.8419, -0.2483, -0.7379],\n",
       "        [ 2.1870, -0.7259,  0.7488, -0.3750]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0445,  1.2542,  0.2437,  0.4232,  0.8193,  1.3041, -1.0165,  0.0656,\n",
       "         0.6642, -0.8419, -0.2483, -0.7379,  2.1870, -0.7259,  0.7488, -0.3750])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0445,  1.2542,  0.2437,  0.4232,  0.8193,  1.3041, -1.0165,  0.0656],\n",
       "        [ 0.6642, -0.8419, -0.2483, -0.7379,  2.1870, -0.7259,  0.7488, -0.3750]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "修改尺寸\n",
    "\"\"\"\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "# -1 表示除给定维度外的其余维度的乘积\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())\n",
    "x\n",
    "y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f03da15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n和 Numpy 数组的转换\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "和 Numpy 数组的转换\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "# Tensor 转换为 Numpy 数组\n",
    "a = torch.ones(5)\n",
    "# 共享内存\n",
    "b = a.numpy()\n",
    "# 新建变量\n",
    "c = np.array(a)\n",
    "type(b)\n",
    "type(c)\n",
    "#  Numpy 数组转换为 Tensor\n",
    "\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "type(a)\n",
    "type(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05f5593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCUDA 张量（在GPU上运算tensors）\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9555,  2.2542,  1.2437,  1.4232],\n",
      "        [ 1.8193,  2.3041, -0.0165,  1.0656],\n",
      "        [ 1.6642,  0.1581,  0.7517,  0.2621],\n",
      "        [ 3.1870,  0.2741,  1.7488,  0.6250]], device='cuda:0')\n",
      "tensor([[ 0.9555,  2.2542,  1.2437,  1.4232],\n",
      "        [ 1.8193,  2.3041, -0.0165,  1.0656],\n",
      "        [ 1.6642,  0.1581,  0.7517,  0.2621],\n",
      "        [ 3.1870,  0.2741,  1.7488,  0.6250]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CUDA 张量（在GPU上运算tensors）\n",
    "\"\"\"\n",
    "# 当 CUDA 可用的时候，可用运行下方这段代码，采用 torch.device() 方法来改变 tensors 是否在 GPU 上进行计算操作\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")     # 定义一个设备对象\n",
    "y = torch.ones_like(x, device=device)  # 显示创建在 GPU 上的一个 tensor\n",
    "x = x.to(device)                       # 也可以采用 .to(\"cuda\") \n",
    "z = x + y\n",
    "print(z)\n",
    "print(z.to(\"cpu\", torch.double))       # .to() 方法也可以改变数值类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13411260",
   "metadata": {},
   "source": [
    "## autograd 自动求导\n",
    "对于 Pytorch 的神经网络来说，非常关键的一个库就是 `autograd` ，它主要是提供了对 `Tensors` 上所有运算操作的自动微分功能，也就是计算梯度的功能。它属于 `define-by-run` 类型框架，即反向传播操作的定义是根据代码的运行方式，因此每次迭代都可以是不同的。\n",
    "\n",
    "接下来会简单介绍一些例子来说明这个库的作用。\n",
    "\n",
    "`torch.Tensor` 是 Pytorch 最主要的库，当设置它的属性 `.requires_grad=True`，那么就会开始追踪在该变量上的所有操作，而完成计算后，可以调用 `.backward()` 并自动计算所有的梯度，得到的梯度都保存在属性 `.grad` 中。\n",
    "\n",
    "而如果是希望防止跟踪历史（以及使用内存），可以将代码块放在 `with torch.no_grad():` 内，这个做法在使用一个模型进行评估的时候非常有用，因为模型会包含一些带有 `requires_grad=True` 的训练参数，但实际上并不需要它们的梯度信息。\n",
    "\n",
    "对于 `autograd` 的实现，还有一个类也是非常重要-- `Function` 。\n",
    "\n",
    "`Tensor` 和 `Function` 两个类是有关联并建立了一个非循环的图，可以编码一个完整的计算记录。每个 `tensor` 变量都带有属性 `.grad_fn` ，该属性引用了创建了这个变量的 `Function` （除了由用户创建的 `Tensors`，它们的 `grad_fn=None` )。\n",
    "\n",
    "如果要进行求导运算，可以调用一个 `Tensor` 变量的方法 `.backward()` 。如果该变量是一个标量，即仅有一个元素，那么不需要传递任何参数给方法 `.backward()`，当包含多个元素的时候，就必须指定一个 `gradient` 参数，表示匹配尺寸大小的 `tensor`，其本质就是计算雅克比向量(vector-Jacobian)乘积。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79b9511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[27., 27.],\n",
       "        [27., 27.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(27., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "x\n",
    "y = x + 2\n",
    "y\n",
    "z = y * y * 3\n",
    "z\n",
    "out = z.mean()\n",
    "out\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b6ab0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 训练train backward 验证/评估的时候不需要梯度\n",
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c600ac0",
   "metadata": {},
   "source": [
    "# 数据加载\n",
    "Pytorch的数据加载主要依赖`torch.utils.data.Dataset`和`torch.utils.data.DataLoader`两个模块，可以完成如下格式的傻瓜式加载\n",
    "``` python\n",
    "train_dataset = MyDataset(train_data_path) # 'MyDataset' 是 'torch.utils.data.Dataset' 的继承\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset)   \n",
    "```\n",
    "## Dataset介绍\n",
    "在`torch.utils.data.Dataset`中我们可以查看`Dataset`的源码 ：\n",
    "``` python\n",
    "class Dataset(Generic[T_co]):\n",
    "    def __getitem__(self, index) -> T_co:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]':\n",
    "        return ConcatDataset([self, other])\n",
    "```\n",
    "\n",
    "Pytorch中，任何基于索引读取数据的类均需继承torch.utils.data.Dataset，该类为数据的读取定义了格式。继承后的子类必须重写`__getitem__()`函数，以此通过给定索引获取对应数据；可以有选择性地重写`__len__()`函数以返回数据集的大小。\n",
    "\n",
    "重写 `__getitem__()` 函数后，我们就可以用索引直接访问对应的数据，如 `data[0]` 表示获取第一个数据。\n",
    "\n",
    "重写 `__len__()` 函数后，我们可以使用 `len(data)` 来获取数据集的大小，即数据条数。\n",
    "## Dataloader 介绍\n",
    "DataLoader为我们提供了对Dataset的读取操作，常用参数有：\n",
    "- `batch_size`(每个batch的大小)，即每轮训练使用的数据条数\n",
    "- `shuffle`(True or False，表示是否进行洗牌打乱操作)，一般训练集设为True，验证集和测试集设为False\n",
    "- `num_workers`(int类型，表示加载数据的时候使用几个子进程)，默认为0，表示使用主进程，推荐和CPU核的个数相同，理论上进程越多加载越块。\n",
    "\n",
    "举例：\n",
    "\n",
    "``` python\n",
    "dl = torch.utils.data.DataLoader(ds_demo, batch_size = 10, shuffle = True, num_workers = 0)\n",
    "# DataLoader返回的是一个可迭代对象，我们可以使用迭代器分次获取数据\n",
    "\n",
    "idata = iter(dl)\n",
    "print(next(idata))\n",
    "\n",
    "# 常见的用法是使用for循环对其进行遍历\n",
    "for i, data in enumerate(dl):\n",
    "    print(i, data)\n",
    "```\n",
    "## 内置数据集\n",
    "`torchvision.datasets` 可以理解为PyTorch团队自定义的dataset，这些dataset帮我们提前处理好了很多计算机视觉相关的数据集，我们拿来就可以直接使用，具体参见官方文档：https://pytorch.org/vision/stable/datasets.html?highlight=datasets\n",
    "\n",
    "同样，也有音频和文本数据集，分别在`torchaudio.datasets` 和 `torchtext.dataset` 下。\n",
    "\n",
    "`torchvision.datasets` 中的 `dataset` 声明对象时，常用的参数有：\n",
    "- `root` : 表示数据存储的路径。\n",
    "- `train` : 布尔类型，表示当前声明的dataset是训练集还是测试集。\n",
    "- `transform` : 对数据的转换，下一节会介绍\n",
    "- `target_transfor`：对label的转换\n",
    "- `download` : 布尔类型，表示是否下载数据集，如果 `root` 下已经存在数据集，则可以设为 False\n",
    "\n",
    "举例：\n",
    "``` python\n",
    "train_data = datasets.CIFAR10(root=\"../Dataset/CIFAR10\", train=True, transform=transform, download=True)  # 训练集\n",
    "test_data = datasets.CIFAR10(root=\"../Dataset/CIFAR10\", train=False, transform=transform, download=True)  # 测试集\n",
    "```\n",
    "使用上述方法，则可以得到对应的`Dataset` 对象，然后使用`DataLoader`装载数据集。\n",
    "\n",
    "## ImageFolder\n",
    "上面说了可以使用重载 `Dataset` 的方式载入自己的数据集，也可以使用 `datasets` 中官方预设的数据集，此外，还可以使用 `ImageFolder` 快速加载一个自己的数据集，`ImageFolder` 假设所有的文件按文件夹保存，每个文件夹下存储同一个类别的图片，文件夹名为类名，比如：\n",
    "``` \n",
    "        root/dog/xxx.png\n",
    "        root/dog/xxy.png\n",
    "        root/dog/[...]/xxz.png\n",
    "\n",
    "        root/cat/123.png\n",
    "        root/cat/nsdf3.png\n",
    "        root/cat/[...]/asd932_.png\n",
    "```\n",
    "声明一个 `ImageFolder` ，常用的参数有：\n",
    "\n",
    "- `root`：在root指定的路径下寻找图片\n",
    "- `transform`：对PIL Image进行的转换操作，transform的输入是使用loader读取图片的返回对象\n",
    "- `target_transform`：对label的转换\n",
    "- `loader`：给定路径后如何读取图片，默认读取为RGB格式的PIL Image对象\n",
    "\n",
    "`ImageFolder` 的上层父类是 `Dataset`，所以可以直接当做`Dataset`使用，此外，它也有自己的一些特殊属性：\n",
    "\n",
    "- `classes (list)`: 返回按字典序排列后的种类名称\n",
    "- `class_to_idx (dict)`: 返回一个字典，表示类名和类编号的映射\n",
    "- `imgs (list)`: 返回一个list，每个元素是一个tuple，由图片路径和所属类别编号组成\n",
    "\n",
    "## 示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2daf6679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n内置数据集的使用\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms, datasets\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m train_data \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mwork\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mStudyCode\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mPycharm\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mNetModel\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCIFAR10\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39m\u001b[43mtransform\u001b[49m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# 训练50000张\u001b[39;00m\n\u001b[0;32m      8\u001b[0m test_data \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mwork\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mStudyCode\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mPycharm\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mNetModel\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCIFAR10\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# 测试10000张\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mlen\u001b[39m(train_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "内置数据集的使用\n",
    "\"\"\"\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data = datasets.CIFAR10(root=\"D:\\\\work\\\\StudyCode\\\\Pycharm\\\\NetModel\\\\Dataset\\\\CIFAR10\", train=True, transform=transform, download=False)  # 训练50000张\n",
    "test_data = datasets.CIFAR10(root=\"D:\\\\work\\\\StudyCode\\\\Pycharm\\\\NetModel\\\\Dataset\\\\CIFAR10\", train=False, transform=transform, download=False)  # 测试10000张\n",
    "len(train_data)\n",
    "\n",
    "train_data.class_to_idx\n",
    "type(train_data[1])\n",
    "plt.imshow(train_data[1][0].numpy().transpose(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c182dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ImageFolder的使用：\n",
    "\"\"\"\n",
    "train_dataset = datasets.ImageFolder(root=\"D:\\\\work\\\\StudyCode\\\\Pycharm\\\\NetModel\\\\Dataset\\\\flower_data\\\\train\")\n",
    "val_dataset = datasets.ImageFolder(root=\"D:\\\\work\\\\StudyCode\\\\Pycharm\\\\NetModel\\\\Dataset\\\\flower_data\\\\val\")\n",
    "train_dataset.class_to_idx\n",
    "train_dataset.imgs[5]\n",
    "train_dataset.imgs[2000]\n",
    "type(train_dataset[0])\n",
    "train_dataset[2200][0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d3904",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "transforms 是图像处理函数，主要用于对索引出来的图片进行 剪切、翻转、平移、仿射等操作，也就是得到我们想要的预处理过程。pytorch 提供的 torchvision.transforms 模块是专门用来进行图像预处理的，主要可以分为以下几种：\n",
    "- 不同形式图像之间的转换\n",
    "- transforms——裁剪\n",
    "- transforms——翻转和旋转\n",
    "\n",
    "## 图像形式转换\n",
    "主要是 PILImage,numpy,Tensor间相互转换。\n",
    "\n",
    "PILImage是Python图像库PIL(Python Image Library)中的一个类，这是python的第三方图像处理库，但是由于其强大的功能与众多的使用人数，几乎已经被认为是python官方图像处理库了。\n",
    "### ToTensor()\n",
    "使用 `torchvision.transforms.ToTensor()` 将PILImage或者numpy的ndarray转化成Tensor\n",
    "- 对于PILImage转化的Tensor，其数据类型是`torch.FloatTensor`\n",
    "- 对于ndarray的数据类型没有限制，但转化成的Tensor的数据类型是由ndarray的数据类型决定的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec275ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PILImage -> tensor\n",
    "from PIL import Image\n",
    "img1 = Image.open('./demo.jpg')\n",
    " \n",
    "PtoT = transforms.ToTensor()(img1)\n",
    "type(PtoT)\n",
    "PtoT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26991d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndarray -> tensor\n",
    "n_out = np.random.rand(100,100,3)\n",
    "n_out.dtype\n",
    "t_out = transforms.ToTensor()(n_out)\n",
    "t_out.type()\n",
    "t_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2095d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor -> PILImage\n",
    "t_out = torch.randn(3,100,100)\n",
    "img1 = transforms.ToPILImage()(t_out.float())\n",
    "img1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945917de",
   "metadata": {},
   "source": [
    "### ToPILImage()\n",
    "\n",
    "将Numpy的ndarray或者Tensor转化成PILImage类型【在数据类型上，两者都有明确的要求】\n",
    "\n",
    "- `ndarray` 的数据类型要求 `dtype=uint8`, range`[0, 255]` and shape H x W x C\n",
    "- `Tensor` 的 `shape` 为 C x H x W 要求是FloatTensor的，不允许`DoubleTensor`或者其他类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndarray -> PILimage\n",
    "data = np.random.randint(0, 255, 30000)\n",
    "print(data.dtype)\n",
    "n_out = data.reshape(100,100,3)\n",
    " \n",
    "#强制类型转换\n",
    "n_out = n_out.astype(np.uint8)\n",
    "print(n_out.dtype)\n",
    " \n",
    "img2 = transforms.ToPILImage()(n_out)\n",
    "img2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f1472e",
   "metadata": {},
   "source": [
    "## 裁剪 Crop\n",
    "主要有：\n",
    "- 中心裁剪： `transforms.CenterCrop()`\n",
    "- 随机裁剪： `transforms.RandomCrop()`\n",
    "- 随机长宽比裁剪： `transforms.RandomResizedCrop()`\n",
    "- 上下左右中心裁剪： `transforms.FiveCrop()`\n",
    "- 上下左右中心裁剪后翻转: `transforms.TenCrop()`\n",
    "## 翻转和旋转 Flip and Rotation\n",
    "- 依概率 p 水平翻转： `transforms.RandomHorizontalFlip(p=0.5)`\n",
    "- 依概率 p 垂直翻转： `transforms.RandomVerticalFlip(p=0.5)`\n",
    "- 随机旋转：`transforms.RandomRotation()`\n",
    "## 图像变换\n",
    "- resize： `transforms.Resize`\n",
    "- 标准化： `transforms.Normalize`\n",
    "- 转为 tensor，并归一化至[0-1]： `transforms.ToTensor`\n",
    "- 填充： `transforms.Pad`\n",
    "- 修改亮度、对比度和饱和度： `transforms.ColorJitter`\n",
    "- 转灰度图： `transforms.Grayscale`\n",
    "- 线性变换： `transforms.LinearTransformation()`\n",
    "- 仿射变换： `transforms.RandomAffine`\n",
    "- 依概率 p 转为灰度图： `transforms.RandomGrayscale`\n",
    "\n",
    "具体使用不进行演示，可以参见：https://blog.csdn.net/Deep_bluce/article/details/111475411\n",
    "\n",
    "## Compose()\n",
    "transform 方法是一个类，我们有两种处理方式，一个是实例化这个 transform 类，然后把图片传入，另一种方式是实例化一个 transforms.Compose() 类。然后对 transforms.Compose 的实例传入图像处理。区别是如果直接实例化 transform 类，一次只能对图像做一种 transform 操作。但是 transforms.Compose() 类支持传入多个 transform 类，即一个 transforms.Compose() 包含多个 transform 类，这样 一次性能够实现多个操作，如下示例中两种写法等价：\n",
    "``` python\n",
    "import torchvision.transforms as transforms\n",
    "pic = imread('...')\n",
    "#---------方 法 1---------- 一次一种处理方式\n",
    "transform = transforms.CenterCrop(720)  # 中心裁剪\n",
    "picProcessed1 = transform(pic)\n",
    "transform = transforms.RandomHorizontalFlip(p=0.5)  # 随机水平翻转\n",
    "picProcessed2 = transform(picProcessed1)\n",
    "\n",
    "#---------方 法 2----------一步到位\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(720)\n",
    "    transforms.RandomHorizontalFlip(p=0.5)\n",
    "    ])\n",
    "picProcessed = transform(pic)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dbd4ec",
   "metadata": {},
   "source": [
    "\n",
    "- torch.nn.Parameter：这是一个**类**，其本质也是一个`Tensor`，只不过被当做模型的参数。即`model.parameters()`会包含这个`parameter`。从而，在参数优化的时候可以自动一起优化，这就不需要我们单独对这个参数进行优化，注意的是 `nn.Parameter`=`nn.parameter.Parameter`\n",
    "- torch.nn.Sequential：一个顺序的容器，将模组添加到里面，在前向传播时，会按照添加的顺序逐一执行容器内的模组。\n",
    "- torch.nn.Module：所有神经网络模组的基类，Pytorch中所有的神经网络都要继承于这个类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a3c83",
   "metadata": {},
   "source": [
    "# 模型搭建 torch.nn\n",
    "nn全称为neural network，意思是神经网络，是torch中构建神经网络的模块\n",
    "## torch.nn.functional\n",
    "该模块包含构建神经网络需要的**函数**，包括卷积层、池化层、激活函数、损失函数、全连接函数等，具体查看官方文档：https://pytorch.org/docs/stable/nn.functional.html#convolution-functions\n",
    "\n",
    "注意这个模块中只包含了函数，所谓函数就是输入数据得到对应的输出，只是简单的数学运算，没有自动更新权重的能力，与后面介绍的Modules不太一样。\n",
    "\n",
    "卷积操作举例如下：\n",
    "<img src=\"https://img.fangkaipeng.com/blog_img/image-20220329101340071.png\" alt=\"image-20220329101340071\" style=\"zoom:50%;\" />\n",
    "\n",
    "下面用`torch.nn.functional.conv2d`模拟一下上图的卷积操作：\n",
    "\n",
    "需要注意的是，在Pytorch中，只要是nn下的包都只支持 mini-batch ，即输入和输出的数据是4维的，每一维度分别表示：(batch大小，输入通道数，高度，宽度)，即`N*C*H*W`，即使只有一张单通道的黑白图片，也要转变为 `1*1*H*W`的形式。\n",
    "> `torch.nn` only supports mini-batches. The entire `torch.nn` package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
    ">\n",
    "> > For example, `nn.Conv2d` will take in a 4D Tensor of `nSamples * nChannels * Height * Width`.\n",
    "> > If you have a single sample, just use `input.unsqueeze(0)` to add a fake batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1af494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    " \n",
    "x = torch.tensor([[1,2,0,3,1],\n",
    "                    [0,1,2,3,1],\n",
    "                    [1,2,1,0,0],\n",
    "                     [5,2,3,1,1],\n",
    "                    [2,1,0,1,1]])\n",
    "kernal = torch.tensor([[1,2,1],\n",
    "                      [0,1,0],\n",
    "                      [2,1,0]])\n",
    "x = torch.reshape(x,[1,1,5,5]) # 拓展成四维\n",
    "kernal = torch.reshape(kernal,[1,1,3,3])\n",
    "out = F.conv2d(x, kernal, stride=1)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2973dc",
   "metadata": {},
   "source": [
    "## torch.nn.Module\n",
    "pytorch中其实一般没有特别明显的Layer和Module的区别，不管是**自定义层**、自定义块、**自定义模型**，都是通过继承Module类完成的。其实Sequential类也是继承自Module类的。\n",
    "\n",
    "torcn.nn是专门为神经网络设计的模块化接口。构建于autograd之上，可以用来定义和运行神经网络。\n",
    "\n",
    "torch.nn.Module 是所有神经网络单元的基类，包含网络各层的定义及forward方法。\n",
    "\n",
    "pytorch里面一切自定义操作基本上都是继承nn.Module类来实现的。\n",
    "\n",
    "在pytorch里面自定义层也是通过继承自nn.Module类来实现的。pytorch里面一般是没有层的概念，层也是当成一个模型来处理的。\n",
    "\n",
    "下面是`Module`中的一些主要函数：\n",
    "\n",
    "``` python\n",
    "\n",
    "class Module(object):\n",
    "    def __init__(self):\n",
    "    def forward(self, *input): # 前向传播\n",
    " \n",
    "    def add_module(self, name, module): # 添加模块\n",
    "    def cuda(self, device=None): # 将模型放入GPU\n",
    "    def cpu(self): # 将模型放入CPU\n",
    "    def __call__(self, *input, **kwargs):  # 实现对象函数化\n",
    "    # 返回参数\n",
    "    def parameters(self, recurse=True):\n",
    "        \"\"\"\n",
    "         Example::\n",
    "\n",
    "            >>> for param in model.parameters():\n",
    "            >>>     print(type(param), param.size())\n",
    "            <class 'torch.Tensor'> (20L,)\n",
    "            <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
    "        \"\"\"\n",
    "    # 当一个迭代器，可以迭代得到模型的参数，返回的是元组类型（参数名称，参数对象）\n",
    "    def named_parameters(self, prefix='', recurse=True): \n",
    "    def children(self):\n",
    "    def named_children(self):\n",
    "    def modules(self): # 返回网络中的所有模组\n",
    "        \"\"\"\n",
    "          Example::\n",
    "\n",
    "                >>> l = nn.Linear(2, 2)\n",
    "                >>> net = nn.Sequential(l, l)\n",
    "                >>> for idx, m in enumerate(net.modules()):\n",
    "                        print(idx, '->', m)\n",
    "\n",
    "                0 -> Sequential(\n",
    "                  (0): Linear(in_features=2, out_features=2, bias=True)\n",
    "                  (1): Linear(in_features=2, out_features=2, bias=True)\n",
    "                )\n",
    "                1 -> Linear(in_features=2, out_features=2, bias=True)\n",
    "        \"\"\"\n",
    "    def named_modules(self, memo=None, prefix=''):\n",
    "    def train(self, mode=True): # 训练模式\n",
    "    def eval(self): # 评估模式\n",
    "    def zero_grad(self): # 将模型参数的所有梯度置为0\n",
    "    def __repr__(self): # 使示例化的对象可以用repr()输出\n",
    "    def __dir__(self): # 返回所有的属性名和方法名\n",
    "\n",
    "```\n",
    "\n",
    "## CNN的基本层\n",
    "### Convolution Layers\n",
    "详情见官方文档：https://pytorch.org/docs/stable/nn.html#convolution-layers\n",
    "\n",
    "Pytorch中实现了很多常用的卷积层，对于图像处理的卷积神经网络来说，最常用的就是 `nn.Conv2d`，即二维卷积层，这里也以此为例。\n",
    "\n",
    "`nn.Conv2d` 也是一个类，继承自 `_ConvNd` ，而 `_ConvNd` 又继承自 `Module`。\n",
    "\n",
    "声明时主要参数：\n",
    "`torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)`\n",
    "- **in_channels** (int) – 输入图像的通道数\n",
    "- **out_channels** (int) – 卷积层输出通道数\n",
    "- **kernel_size** (int *or* tuple) – 卷积核大小\n",
    "- **stride** (int *or* tuple*,* *optional*) – 卷积核步长\n",
    "- **padding** (int*,* tuple *or* str*,* *optional*) – 在外层填充圈数，Default: 0\n",
    "- **dilation** (int *or* tuple*,* *optional*) – 卷积核中挖洞，Default: 1（表示不挖洞）\n",
    "- **bias** (bool*,* *optional*) – 是否添加偏置项 Default: `True`\n",
    "\n",
    "其中输入图像和输出图像的大小计算方式如下图：\n",
    "<img src=\"https://img.fangkaipeng.com/blog_img/20220529200616.png\" alt=\"image-20220529200616007\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b234da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# With square kernels and equal stride\n",
    "conv = nn.Conv2d(16, 33, 3, stride=2, padding=2)\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "input.shape\n",
    "output = conv(input) ## __call__实习对象函数式调用\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa269437",
   "metadata": {},
   "source": [
    "### Pooling layers\n",
    "具体见官方文档：https://pytorch.org/docs/stable/nn.html#pooling-layers\n",
    "\n",
    "实现了常用的池化层，如最大池化，平均池化等。以 `nn.MaxPool2d` 为例：\n",
    "\n",
    "池化层主要是用于缩小图片的维度，减少冗余特征，从而加快训练速度，经过池化层处理后的图像一般通道数不变，只会改变长宽。\n",
    "\n",
    "主要参数如下：\n",
    "\n",
    "- kernel_size – the size of the window to take a max over\n",
    "\n",
    "- stride – the stride of the window. Default value is kernel_size\n",
    "\n",
    "- padding – implicit zero padding to be added on both sides\n",
    "\n",
    "- dilation – a parameter that controls the stride of elements in the window\n",
    "\n",
    "参数含义类似卷积层，不详细解释，输入输出图像的长宽计算公式：\n",
    "\n",
    "<img src=\"https://img.fangkaipeng.com/blog_img/20220530072457.png\" alt=\"image-20220530072414394\" style=\"zoom:50%;\" />\n",
    "\n",
    "可以看出，计算公式和卷积相同，区别在于卷积层输出的通道数等于卷积个数，池化层输出通道数和输入的相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dceeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool of square window of size=3, stride=2\n",
    "MaxPool2d = nn.MaxPool2d(3, stride=2)\n",
    "input = torch.randn(20, 16, 50, 32)\n",
    "output = MaxPool2d(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c8e56e",
   "metadata": {},
   "source": [
    "### 一些其他常用的层 \n",
    "- Non-linear Activations,非线性激活层，比如 `nn.ReLU` `nn.Tanh` `nn.LogSigmoid` 等，其中部分可以设置参数 `inplace`，True表示在原数据上操作，False表示新建一个对象计算。\n",
    "- Normalization Layers，归一化层\n",
    "- Linear Layers，线性变换层，主要用于改变维度\n",
    "- Dropout Layers，随机失活层，主要参数 `p` 表示失活概率\n",
    "- nn.Flatten,展平tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb87d2",
   "metadata": {},
   "source": [
    "## 搭建一个简易CNN\n",
    "我们在定义自已的网络的时候，需要继承 `nn.Module` 类，并重新实现构造函数 `__init__` 构造函数和 `forward` 这两个方法。继承 `nn.Module` 类在自定义类时即可实现，注意在构造函数中也需要先调用父类的构造函数，forward 接受输入进行前向传播后返回输出结果，由于`model`类实现了 `__call__` ，所以可以直接使用 `对象名()` 的方式进行前向传播，具体如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "    \n",
    "    def forward(self,input):\n",
    "        output = input + 1\n",
    "        return output\n",
    "    \n",
    "model = Model()\n",
    "x = torch.tensor(1)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe2c1f",
   "metadata": {},
   "source": [
    "在实现`__init__` 和 `forward` 时有一些注意技巧：\n",
    "\n",
    "（1）一般把网络中具有可学习参数的层（如全连接层、卷积层等）放在构造函数 `__init__()` 中，当然我也可以把不具有参数的层也放在里面；\n",
    "\n",
    "（2）一般把不具有可学习参数的层(如ReLU、dropout、BatchNormanation层)可放在构造函数中，也可不放在构造函数中，如果不放在构造函数`__init__`里面，则在 `forward` 方法里面可以使用 `nn.functional` 来代替。\n",
    "\n",
    "（3）`forward` 方法是必须要重写的，它是实现模型的功能，实现各个层之间的连接关系的核心。\n",
    "\n",
    "是否将不具有参数的层放入构造函数的区别在于，只有在构造函数中的层才属于模型的层，其参数才会在训练时被更新，而有些层本来就没有参数无需训练，所以可以不用放在构造函数内，只要在 `forward` 中实现即可，比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150f9049",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    " \n",
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()  # 第一句话，调用父类的构造函数\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.relu1=torch.nn.ReLU()\n",
    "        self.max_pooling1=torch.nn.MaxPool2d(2,1)\n",
    " \n",
    "        self.conv2 = torch.nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.relu2=torch.nn.ReLU()\n",
    "        self.max_pooling2=torch.nn.MaxPool2d(2,1)\n",
    " \n",
    "        self.dense1 = torch.nn.Linear(32 * 3 * 3, 128)\n",
    "        self.dense2 = torch.nn.Linear(128, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.max_pooling1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.max_pooling2(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    " \n",
    "model = MyNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdba682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    " \n",
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()  # 第一句话，调用父类的构造函数\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.conv2 = torch.nn.Conv2d(3, 32, 3, 1, 1)\n",
    " \n",
    "        self.dense1 = torch.nn.Linear(32 * 3 * 3, 128)\n",
    "        self.dense2 = torch.nn.Linear(128, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    " \n",
    "model = MyNet()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28874a84",
   "metadata": {},
   "source": [
    "## torch.nn.parameter\n",
    "torch.nn.Parameter是继承自torch.Tensor的子类，其主要作用是作为nn.Module中的可训练参数使用。它与torch.Tensor的区别就是nn.Parameter会自动被认为是module的可训练参数，即加入到parameter()这个迭代器中去；而module中非nn.Parameter()的普通tensor是不在parameter中的。nn.Parameter的对象的requires_grad属性的默认值是True，即是可被训练的，这与torth.Tensor对象的默认值相反。在nn.Module类中，pytorch也是使用nn.Parameter来对每一个module的参数进行初始化的。以nn.Linear为例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ad717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Network(nn.Module):\n",
    "    def __init__(self,in_dim,hid,out_dim):\n",
    "        super(NN_Network, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_dim,hid)\n",
    "        self.linear2 = nn.Linear(hid,out_dim)\n",
    "        \n",
    "        self.linear1.weight = torch.nn.Parameter(torch.zeros(in_dim,hid))\n",
    "        self.linear1.bias = torch.nn.Parameter(torch.ones(hid))\n",
    "        self.linear2.weight = torch.nn.Parameter(torch.zeros(in_dim,hid))\n",
    "        self.linear2.bias = torch.nn.Parameter(torch.ones(hid))\n",
    "\n",
    "    def forward(self, input_array):\n",
    "        h = self.linear1(input_array)\n",
    "        y_pred = self.linear2(h)\n",
    "        return y_pred\n",
    "\n",
    "in_d = 5\n",
    "hidn = 2\n",
    "out_d = 3\n",
    "net = NN_Network(in_d, hidn, out_d)\n",
    "\n",
    "# 读取parameters，因为net.parameters是个生成器，所以需要去遍历输出\n",
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ea660",
   "metadata": {},
   "source": [
    "## torch.nn.Sequential\n",
    "前面搭建一个简易CNN的章节中，定义了很多层，然后再 `forward` 实现时需要将这些层连接起来（前一层输出作为后一层输入），这样比较繁琐，对此我们可以使用 `Sequential` 来实现层的“打包”。\n",
    "\n",
    "主要有三种使用方法：\n",
    "\n",
    "``` python\n",
    "************torch.nn.Sequential************\n",
    "-------顺序容器\n",
    "\n",
    "#写法一：\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 20, 5)\n",
    ")\n",
    "\n",
    "#写法二：\n",
    "net = nn.Sequential()\n",
    "net.add_module('conv2d', nn.Conv2d(1, 20, 5))\n",
    "\n",
    "#写法三：\n",
    "from collections import OrderedDict\n",
    "\n",
    "net = nn.Sequential(OrderedDict([\n",
    "   ('conv2d', nn.Conv2d(1, 20, 5))\n",
    "    #.....\n",
    "    \n",
    "]))\n",
    "\n",
    "```\n",
    "\n",
    "示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,in_dim,hid,out_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer = torch.nn.Sequential(\n",
    "            nn.Conv2d(1, 20, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, 5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ouput = self.layer(x)\n",
    "        return ouput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7f586b",
   "metadata": {},
   "source": [
    "# 模型训练\n",
    "\n",
    "Pytorch中模型训练步骤还是非常清晰的：\n",
    "\n",
    "- 数据载入及处理\n",
    "- 模型定义\n",
    "- 超参数设置（损失函数定义、优化器定义、训练轮数）\n",
    "- 训练模型\n",
    "  - 读取一个batch的数据，并前向传播\n",
    "  - 计算损失值\n",
    "  - 反向传播计算梯度\n",
    "  - 优化器优化模型\n",
    "  - 循环执行上述过程直到规定轮数\n",
    "- 评估模型（非必须）\n",
    "- 测试模型\n",
    "\n",
    "其中除了损失函数和优化器的定义和使用没有提到，其余内容在前文都有介绍，下面直接搭建一个CNN网络，展示一个网络的完整训练流程：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f2ba12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n依赖包载入、数据集载入和划分\\n以CIFAR10作为模型训练的数据集，训练集50000张，测试集10000张图片\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86176\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集长度为：50000 \n",
      "验证数据集的长度为：10000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "依赖包载入、数据集载入和划分\n",
    "以CIFAR10作为模型训练的数据集，训练集50000张，测试集10000张图片\n",
    "\"\"\"\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "# 准备数据集\n",
    "train_data = datasets.CIFAR10(root=\"./\", train=True, transform=transform, download=True)\n",
    "test_data = datasets.CIFAR10(root=\"./\", train=False, transform=transform, download=True)\n",
    "\n",
    "# length\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "print(\"训练数据集长度为：{} \\n验证数据集的长度为：{}\".format(train_data_size, test_data_size))\n",
    "\n",
    "\n",
    "\n",
    "# 利用DataLoader加载数据集\n",
    "train_dataloader = DataLoader(train_data, shuffle=True,batch_size=32, num_workers= 8)\n",
    "test_dataloader = DataLoader(test_data, shuffle=False,batch_size=10000, num_workers= 8)\n",
    "\n",
    "# test_iter = iter(test_dataloader)\n",
    "# test_imgs, test_labels = test_iter.next()\n",
    "# test_imgs.shape\n",
    "# test_imgs = test_imgs.to(device)\n",
    "# test_labels = test_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf19d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 5),  # input_size:[3,32,32]     out_size: [16,28,28]\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(2),  # input_size: [16,28,28]   out_size: [16,14,14]\n",
    "            nn.Conv2d(16, 32, 5),  # input_size: [16,14,14]    out_size: [32,10,10]\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(2),  # input_size: [32,10,10]   out_size: [32,5,5]\n",
    "            nn.Flatten(),  # 矩阵展开\n",
    "            nn.Linear(32 * 5 * 5, 120), nn.Sigmoid(),\n",
    "            nn.Linear(120, 84), nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "850c6be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------第 1 轮训练开始-------\n",
      "train epoch[1/5] loss:1.400: 100%|█████████████████████████████████████████████████| 1563/1563 [00:24<00:00, 62.62it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m             accurcy \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m targets)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     57\u001b[0m             total_accuracy \u001b[38;5;241m=\u001b[39m total_accuracy \u001b[38;5;241m+\u001b[39m accurcy\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[epoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] train_loss: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m  val_accuracy: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m---> 60\u001b[0m               (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_loader\u001b[49m), total_accuracy\u001b[38;5;241m/\u001b[39mtest_data_size))\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# writer.add_scalar(\"test_loss\", total_accuracy/test_data_size, total_test_step)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# 保存每一次训练的模型\u001b[39;00m\n\u001b[0;32m     66\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.path\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(total_train_step))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet()\n",
    "model = model.to(device)  # 设置在GPU中训练\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# 优化器\n",
    "learning_rate = 0.005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 设置训练网络的参数\n",
    "total_train_step = 0\n",
    "total_test_step = 0\n",
    "epochs = 5\n",
    "\n",
    "# 添加tensorboard\n",
    "#writer = SummaryWriter(\"./logs_train_CIFAR10\")\n",
    "# 开始训练 \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"-------第 {} 轮训练开始-------\".format(epoch+1))\n",
    "    train_bar = tqdm(train_dataloader, file=sys.stdout)\n",
    "    #model.train() #网络中有特殊层的时候需要加上，具体看文档，但加上不会出错\n",
    "    running_loss = 0.0\n",
    "    for step,data in enumerate(train_bar):\n",
    "        imgs, targets = data\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_step = total_train_step + 1\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,epochs, loss)\n",
    "        \n",
    "    # 测试步骤开始\n",
    "   # model.eval() # 网络中有特殊层的时候需要加上，具体看文档，但加上不会出错\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad(): # 取消梯度跟踪，进行测试 重要！！！\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_test_loss = total_test_loss + loss.item()\n",
    "            accurcy = (torch.max(outputs, dim=1)[1] == targets).sum().item()\n",
    "            total_accuracy = total_accuracy + accurcy\n",
    "            \n",
    "    print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / len(train_loader), total_accuracy/test_data_size))\n",
    "     \n",
    "    # writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    # writer.add_scalar(\"test_loss\", total_accuracy/test_data_size, total_test_step)\n",
    "\n",
    "# 保存每一次训练的模型\n",
    "torch.save(model, \"model_{}.path\".format(total_train_step))\n",
    "print(\"------训练完毕-------\")\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a3c0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d19dbb5",
   "metadata": {},
   "source": [
    "# 训练可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645420a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
